{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b121e1-6e79-48ce-9ddd-92e2a677b1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import zmq\n",
    "import io\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import autograd\n",
    "from torch.utils.data import DataLoader\n",
    "import torch as th\n",
    "from buffer import serialize, de_serialize\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import mnist\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cde2eb-276e-4e0e-822a-d8cd5f5ac28e",
   "metadata": {},
   "source": [
    "import all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5837ca-c2d2-4056-a09d-fa6c1b3e7f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Connecting to hello world server…\")\n",
    "context = zmq.Context()\n",
    "socket = context.socket(zmq.REQ)\n",
    "socket.connect(\"tcp://localhost:5555\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2555e1fa-11b1-463c-ad81-39b89cdd2795",
   "metadata": {},
   "source": [
    "establish client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b91b28d-4f85-4d95-ad34-0bb9319536c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetClient(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetClient, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.conv1(x)))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = self.pool3(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 128*3*3)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "class RemotePassBegin(autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        buffer = io.BytesIO()\n",
    "        th.save({\n",
    "            \"flag\": 0,  # forward\n",
    "            \"data\": input\n",
    "        }, buffer)\n",
    "\n",
    "        socket.send(buffer.getvalue())\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        # return grad_output\n",
    "        return de_serialize(socket.recv())\n",
    "\n",
    "\n",
    "class RemotePassEnd(autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # ctx.input = input\n",
    "        return de_serialize(socket.recv())\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        buffer = io.BytesIO()\n",
    "        th.save({\n",
    "            \"flag\": 1,  # backward\n",
    "            \"data\": grad_output\n",
    "        }, buffer)\n",
    "\n",
    "        socket.send(buffer.getvalue())\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9795b4-3fda-48ad-8c4f-3962cdd6c705",
   "metadata": {},
   "source": [
    "net body and pass-recv functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5239a96-b16c-465f-9998-ee80a2072b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_client = NetClient()\n",
    "train_batch_size = 128\n",
    "test_batch_size = 64\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "num_epoches = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e38d6c-6e9c-4027-9bc3-3c9e4bcad3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two datasets\n",
    "transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "train_dataset = mnist.MNIST(\n",
    "    './data', train=True, transform=transforms, download=True)\n",
    "test_dataset = mnist.MNIST('./data', train=False, transform=transforms)\n",
    "# iterate\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(net_client.parameters(),\n",
    "                      lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6a26a6-245a-4afb-a240-6d4374faf04a",
   "metadata": {},
   "source": [
    "create dataloader and testloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b6840d-da6d-4047-975d-86006153112e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_accs = []\n",
    "\n",
    "\n",
    "def train():\n",
    "    for epoch in range(num_epoches):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        time_start = time.time()\n",
    "        for img, label in train_loader:\n",
    "            img = img\n",
    "            label = label\n",
    "            x = net_client(img)\n",
    "            x = RemotePassBegin.apply(x)\n",
    "            x = RemotePassEnd.apply(x)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(x, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # calculate loss\n",
    "            train_loss += loss.item()\n",
    "            # calculate accuracy\n",
    "            pred = x.argmax(dim=1)\n",
    "            train_acc += (pred == label).sum().item() / img.size(0)\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_acc / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_accs)\n",
    "        # 日志输出\n",
    "        time_end = time.time()\n",
    "        print('time cost', time_end-time_start, 's')\n",
    "        print(\"Epoch: {}, Train loss: {:.4f}, Train acc: {:.4f}\".format(\n",
    "            epoch, train_loss, train_acc))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7460401b-f1a7-49ce-91f9-2af934a3221d",
   "metadata": {},
   "source": [
    "train functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46819f84-d317-44ad-936e-db9cad1ddb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
