{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64fb4ca-e7d2-4960-ab33-4ce2d762ed0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed.rpc as rpc\n",
    "import torch.multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "import torch.nn.functional as F\n",
    "from torch import autograd\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import mnist\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea77126-4365-4328-9c45-d28dc3e10b7a",
   "metadata": {},
   "source": [
    "import denpendencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c45f3b-c269-4e0b-90d9-1efba8d5fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['MASTER_ADDR'] = '127.0.0.1'\n",
    "os.environ['MASTER_PORT'] = '29503'\n",
    "rank = 1\n",
    "world_size = 2\n",
    "dist.init_process_group(backend='gloo', rank=rank, world_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9316eca0-eadf-4f72-aeb7-0a1febd77121",
   "metadata": {},
   "source": [
    "initialize and connect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162e0a7c-f080-4e64-8de4-d2a44ff8f6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RemotePassBegin(autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        dist.send(torch.tensor(0), 0)\n",
    "        dist.send(input, 0)\n",
    "        return input\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_outputs):\n",
    "        x = torch.rand([128, 1152])\n",
    "        \n",
    "        dist.recv(x, 0)\n",
    "        return x\n",
    "\n",
    "\n",
    "class RemotePassEnd(autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        # ctx.input = input\n",
    "        x = torch.rand([128, 10])\n",
    "        dist.recv(x, 0)\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        dist.send(torch.tensor(1), 0)\n",
    "        dist.send(grad_output, 0)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dd2e2c-ba04-469e-97e9-03b3d0334279",
   "metadata": {},
   "source": [
    "build network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793478bb-16ba-48b6-8c5c-9f29161dd732",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = nn.CrossEntropyLoss()\n",
    "net = NetClient()\n",
    "\n",
    "\n",
    "train_batch_size = 128\n",
    "test_batch_size = 64\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "num_epoches = 10\n",
    "# create two datasets\n",
    "transforms = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "train_dataset = mnist.MNIST(\n",
    "    './data', train=True, transform=transforms, download=True)\n",
    "test_dataset = mnist.MNIST('./data', train=False, transform=transforms)\n",
    "# iterate\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(),\n",
    "                      lr=learning_rate, momentum=momentum)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61756ec3-2241-41eb-a43c-ff88c4163381",
   "metadata": {},
   "source": [
    "optimizer, datasets and net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd89297-10e1-4d90-a9e1-7feb00c7164a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    for epoch in range(num_epoches):\n",
    "        train_loss = 0\n",
    "        train_acc = 0\n",
    "        time_start = time.time()\n",
    "        i = 0\n",
    "        for img, label in train_loader:\n",
    "            i = i +1\n",
    "            if i == 468:\n",
    "                break\n",
    "            img = img\n",
    "            label = label\n",
    "            x = net(img)\n",
    "            x = RemotePassBegin.apply(x)\n",
    "            x = RemotePassEnd.apply(x)\n",
    "            criterion = nn.CrossEntropyLoss()\n",
    "            loss = criterion(x, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # calculate loss\n",
    "            train_loss += loss.item()\n",
    "            # calculate accuracy\n",
    "            pred = x.argmax(dim=1)\n",
    "            train_acc += (pred == label).sum().item() / img.size(0)\n",
    "            #print(i)\n",
    "        train_loss = train_loss / len(train_loader)\n",
    "        train_acc = train_acc / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_accs)\n",
    "        # 日志输出\n",
    "        time_end = time.time()\n",
    "        print('time cost', time_end-time_start, 's')\n",
    "        print(\"Epoch: {}, Train loss: {:.4f}, Train acc: {:.4f}\".format(\n",
    "            epoch, train_loss, train_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526abae3-0847-4fbd-b6de-52794b934697",
   "metadata": {},
   "source": [
    "define training functions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
